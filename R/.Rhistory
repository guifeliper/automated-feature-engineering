# install.packages(c("mfe"), dependencies=TRUE, repos='http:/cran.rstudio.com/)
library(mfe)
setwd('./data/')
setwd('/Users/guifeliper/Thesis/autoML/automated-feature-engineering/R/Data')
# Definition of datasets
datasets <- list.files('./base/',full.names = TRUE)
# Definition of datasets
datasets <- list.files('./base/',full.names = false)
# Definition of datasets
datasets <- list.files('./base/',full.names = FALSE)
# Get meta knowledge
metadata <- read.csv(paste(sep="", "./metadata.csv"), header=TRUE, sep=",", row.names = 1)
#Process the metafeatures
creating_metafeatures <- function(ds, type, groups) {
print(paste("Processing", type,  "for", ds, "..."))
d <- read.csv(paste0("./", type , "/", ds), header=TRUE, sep=",")
d.features <- subset(d, select=-c(class))
d.labels <- d[,'class']
d.info <- tryCatch(
metafeatures(d.features, d.labels, groups=groups),
error=function(e) {print(paste(e));NaN}
)
i = 1
for (info in d.info)
{
name = paste0(type,".", tolower(names(d.info)[i]))
metadata[c(ds), c(name)] <- info
i = i + 1
}
return(metadata)
}
for (ds in datasets)
{
start.time <- Sys.time()
metadata<- creating_metafeatures(ds, 'extended', c("general", "statistical","model.based"))
metadata<- creating_metafeatures(ds, 'base', c("general", "statistical","model.based"))
gc()
#Printing
end.time <- Sys.time()
time.taken <- end.time - start.time
print(time.taken)
## Saving
write.csv(metadata, file = "./metadata.csv")
}
d <- read.csv(paste0("./", type , "/", ds), header=TRUE, sep=",")
paste0("./", type , "/", ds)
d <- read.csv(paste0("./base/", ds), header=TRUE, sep=",")
View(d)
#!/usr/bin/Rscript
# install.packages(c("mfe"), dependencies=TRUE, repos='http:/cran.rstudio.com/)
library(mfe)
setwd('/Users/guifeliper/Thesis/autoML/automated-feature-engineering/R/Data')
# Definition of datasets
datasets <- list.files('./base/',full.names = FALSE)
# Get meta knowledge
metadata <- read.csv(paste(sep="", "./metadata.csv"), header=TRUE, sep=",", row.names = 1)
#Process the metafeatures
creating_metafeatures <- function(ds, type, groups) {
print(paste("Processing", type,  "for", ds, "..."))
d <- read.csv(paste0("./", type , "/", ds), header=TRUE, sep=",")
d.features <- subset(d, select=-c(class))
d.labels <- d[,'class']
d.info <- tryCatch(
metafeatures(d.features, d.labels, groups=groups),
error=function(e) {print(paste(e));NaN}
)
i = 1
for (info in d.info)
{
name = paste0(type,".", tolower(names(d.info)[i]))
metadata[c(ds), c(name)] <- info
i = i + 1
}
return(metadata)
}
# Process datasets
for (ds in datasets)
{
start.time <- Sys.time()
# metadata<- creating_metafeatures(ds, 'extended', c("general", "statistical","model.based"))
metadata<- creating_metafeatures(ds, 'base', c("general", "statistical","model.based"))
gc()
#Printing
end.time <- Sys.time()
time.taken <- end.time - start.time
print(time.taken)
## Saving
write.csv(metadata, file = "./metadata.csv")
}
#!/usr/bin/Rscript
# install.packages(c("mfe"), dependencies=TRUE, repos='http:/cran.rstudio.com/)
library(mfe)
setwd('/Users/guifeliper/Thesis/autoML/automated-feature-engineering/R/Data')
# Definition of datasets
datasets <- list.files('./base/',full.names = FALSE)
# Get meta knowledge
metadata <- read.csv(paste(sep="", "./metadata.csv"), header=TRUE, sep=",", row.names = 1)
#Process the metafeatures
creating_metafeatures <- function(ds, type, groups) {
print(paste("Processing", type,  "for", ds, "..."))
d <- read.csv(paste0("./", type , "/", ds), header=TRUE, sep=",")
d.features <- subset(d, select=-c(class))
d.labels <- d[,'class']
d.info <- tryCatch(
metafeatures(d.features, d.labels, groups=groups),
error=function(e) {print(paste(e));NaN}
)
i = 1
for (info in d.info)
{
name = paste0(type,".", tolower(names(d.info)[i]))
metadata[c(ds), c(name)] <- info
i = i + 1
}
return(metadata)
}
# Process datasets
for (ds in datasets)
{
start.time <- Sys.time()
metadata<- creating_metafeatures(ds, 'extended', c("general", "statistical","model.based"))
metadata<- creating_metafeatures(ds, 'base', c("general", "statistical","model.based"))
gc()
#Printing
end.time <- Sys.time()
time.taken <- end.time - start.time
print(time.taken)
## Saving
write.csv(metadata, file = "./metadata.csv")
}
#!/usr/bin/Rscript
# install.packages(c("mfe"), dependencies=TRUE, repos='http:/cran.rstudio.com/)
library(mfe)
setwd('/Users/guifeliper/Thesis/autoML/automated-feature-engineering/R/Data')
# Definition of datasets
datasets <- list.files('./base/',full.names = FALSE)
# Get meta knowledge
metadata <- read.csv(paste(sep="", "./metadata.csv"), header=TRUE, sep=",", row.names = 1)
#Process the metafeatures
creating_metafeatures <- function(ds, type, groups) {
print(paste("Processing", type,  "for", ds, "..."))
d <- read.csv(paste0("./", type , "/", ds), header=TRUE, sep=",")
d.features <- subset(d, select=-c(class))
d.labels <- d[,'class']
d.info <- tryCatch(
metafeatures(d.features, d.labels, groups=groups),
error=function(e) {print(paste(e));NaN}
)
i = 1
for (info in d.info)
{
name = paste0(type,".", tolower(names(d.info)[i]))
metadata[c(ds), c(name)] <- info
i = i + 1
}
return(metadata)
}
# Process datasets
# Parallel only for Linux and OS X
mclapply(datasets, function(ds){
start.time <- Sys.time()
metadata<- creating_metafeatures(ds, 'extended', c("general", "statistical","model.based"))
metadata<- creating_metafeatures(ds, 'base', c("general", "statistical","model.based"))
gc()
#Printing
end.time <- Sys.time()
time.taken <- end.time - start.time
print(time.taken)
## Saving
write.csv(metadata, file = "./metadata.csv")
}, mc.cores=8L)
#!/usr/bin/Rscript
# install.packages(c("mfe"), dependencies=TRUE, repos='http:/cran.rstudio.com/)
library(mfe)
library(parallel)
setwd('/Users/guifeliper/Thesis/autoML/automated-feature-engineering/R/Data')
# Definition of datasets
datasets <- list.files('./base/',full.names = FALSE)
# Get meta knowledge
metadata <- read.csv(paste(sep="", "./metadata.csv"), header=TRUE, sep=",", row.names = 1)
#Process the metafeatures
creating_metafeatures <- function(ds, type, groups) {
print(paste("Processing", type,  "for", ds, "..."))
d <- read.csv(paste0("./", type , "/", ds), header=TRUE, sep=",")
d.features <- subset(d, select=-c(class))
d.labels <- d[,'class']
d.info <- tryCatch(
metafeatures(d.features, d.labels, groups=groups),
error=function(e) {print(paste(e));NaN}
)
i = 1
for (info in d.info)
{
name = paste0(type,".", tolower(names(d.info)[i]))
metadata[c(ds), c(name)] <- info
i = i + 1
}
return(metadata)
}
# Process datasets
# Parallel only for Linux and OS X
mclapply(datasets, function(ds){
start.time <- Sys.time()
metadata<- creating_metafeatures(ds, 'extended', c("general", "statistical","model.based"))
metadata<- creating_metafeatures(ds, 'base', c("general", "statistical","model.based"))
gc()
#Printing
end.time <- Sys.time()
time.taken <- end.time - start.time
print(time.taken)
## Saving
write.csv(metadata, file = "./metadata.csv")
}, mc.cores=8L)
#!/usr/bin/Rscript
# install.packages(c("mfe"), dependencies=TRUE, repos='http:/cran.rstudio.com/)
library(mfe)
library(parallel)
setwd('/Users/guifeliper/Thesis/autoML/automated-feature-engineering/R/Data')
# Definition of datasets
datasets <- list.files('./base/',full.names = FALSE)
# Get meta knowledge
metadata <- read.csv(paste(sep="", "./metadata.csv"), header=TRUE, sep=",", row.names = 1)
#Process the metafeatures
creating_metafeatures <- function(ds, type, groups) {
print(paste("Processing", type,  "for", ds, "..."))
d <- read.csv(paste0("./", type , "/", ds), header=TRUE, sep=",")
d.features <- subset(d, select=-c(class))
d.labels <- d[,'class']
d.info <- tryCatch(
metafeatures(d.features, d.labels, groups=groups),
error=function(e) {print(paste(e));NaN}
)
i = 1
for (info in d.info)
{
name = paste0(type,".", tolower(names(d.info)[i]))
metadata[c(ds), c(name)] <- info
i = i + 1
}
return(metadata)
}
# Process datasets
# Parallel only for Linux and OS X
mclapply(datasets, function(ds){
start.time <- Sys.time()
metadata<- creating_metafeatures(ds, 'extended', c("general", "statistical","model.based"))
metadata<- creating_metafeatures(ds, 'base', c("general", "statistical","model.based"))
gc()
#Printing
end.time <- Sys.time()
time.taken <- end.time - start.time
print(time.taken)
## Saving
write.csv(metadata, file = "./metadata.csv")
}, mc.cores=8L)
library(parallel)
library(mfe)
# Definition of datasets
datasets <-  list.files('./data/base/',full.names = FALSE)
mclapply(datasets, function(ds){
metadata <- data.frame(read.csv(paste0("./data/filter_selection/", ds), header=TRUE, sep=","))
rownames(metadata) <- make.names(metadata$feature, unique = TRUE)
metadata <- metadata[ , -which(names(metadata) %in% c("X"))]
X <- read.csv(paste0("./data/base/", ds), header=TRUE, sep=",")
X_derived <- read.csv(paste0("./data/filter_extended/", ds), header=TRUE, sep=",")
# Removing the base features
dropList <- colnames(X)
d.features <- X_derived[, !colnames(X_derived) %in% dropList]
#Selecting class
d.labels <- X[,'class']
j = 1
numberOfFeatures = ncol(d.features)
columns <- make.names(colnames(d.features))
for (column in c(columns)){
print(paste(j, 'of', numberOfFeatures, 'on', ds))
d.extX <- X_derived[, !colnames(X_derived) %in% column]
d.info <- tryCatch(
metafeatures(d.extX, d.labels, groups=c("general","statistical", "model.based" )),
error=function(e) {print(paste(e));NaN}
)
i = 1
for (info in d.info)
{
name = paste0(tolower(names(d.info)[i]))
metadata[c(column), c(name)] <- info
i = i + 1
}
j = j + 1
}
# Saving
write.csv(metadata, file = paste0("./data/mfe_ext_x/", ds))
ds
}, mc.cores=8L)
library(parallel)
library(mfe)
# Definition of datasets
datasets <-  list.files('./data/base/',full.names = FALSE)
setwd('/Users/guifeliper/Thesis/autoML/automated-feature-engineering/R/Data')
# Definition of datasets
datasets <-  list.files('./base/',full.names = FALSE)
#set the directory
setwd('/Users/guifeliper/Thesis/autoML/automated-feature-engineering/R')
# Definition of datasets
datasets <-  list.files('./data/base/',full.names = FALSE)
# Definition of datasets
datasets <- list.files('./data/base/',full.names = FALSE)
# Get meta knowledge
metadata <- read.csv(paste(sep="", "./data/metadata.csv"), header=TRUE, sep=",", row.names = 1)
# Definition of datasets
datasets <-  list.files('./data/base/',full.names = FALSE)
# Definition of datasets
datasets <-  list.files('./data/base/',full.names = FALSE)
mclapply(datasets, function(ds){
metadata <- data.frame(read.csv(paste0("./data/filter_selection/", ds), header=TRUE, sep=","))
rownames(metadata) <- make.names(metadata$feature, unique = TRUE)
metadata <- metadata[ , -which(names(metadata) %in% c("X"))]
X <- read.csv(paste0("./data/base/", ds), header=TRUE, sep=",")
X_derived <- read.csv(paste0("./data/filter_extended/", ds), header=TRUE, sep=",")
# Removing the base features
dropList <- colnames(X)
d.features <- X_derived[, !colnames(X_derived) %in% dropList]
#Selecting class
d.labels <- X[,'class']
j = 1
numberOfFeatures = ncol(d.features)
columns <- make.names(colnames(d.features))
for (column in c(columns)){
print(paste(j, 'of', numberOfFeatures, 'on', ds))
d.extX <- X_derived[, !colnames(X_derived) %in% column]
d.info <- tryCatch(
metafeatures(d.extX, d.labels, groups=c("general","statistical", "model.based" )),
error=function(e) {print(paste(e));NaN}
)
i = 1
for (info in d.info)
{
name = paste0(tolower(names(d.info)[i]))
metadata[c(column), c(name)] <- info
i = i + 1
}
j = j + 1
}
# Saving
write.csv(metadata, file = paste0("./data/mfe_ext_x/", ds))
ds
}, mc.cores=8L)
ds <- "glass.csv"
metadata <- data.frame(read.csv(paste0("./data/filter_selection/", ds), header=TRUE, sep=","))
rownames(metadata) <- make.names(metadata$feature, unique = TRUE)
metadata <- metadata[ , -which(names(metadata) %in% c("X"))]
X <- read.csv(paste0("./data/base/", ds), header=TRUE, sep=",")
X_derived <- read.csv(paste0("./data/filter_extended/", ds), header=TRUE, sep=",")
X_derived <- read.csv(paste0("./data/filter_extended/", ds), header=TRUE, sep=",")
# Removing the base features
dropList <- colnames(X)
d.features <- X_derived[, !colnames(X_derived) %in% dropList]
#Selecting class
d.labels <- X[,'class']
j = 1
numberOfFeatures = ncol(d.features)
columns <- make.names(colnames(d.features))
mclapply(datasets, function(ds){
metadata <- data.frame(read.csv(paste0("./data/filter_selection/", ds), header=TRUE, sep=","))
rownames(metadata) <- make.names(metadata$feature, unique = TRUE)
metadata <- metadata[ , -which(names(metadata) %in% c("X"))]
X <- read.csv(paste0("./data/base/", ds), header=TRUE, sep=",")
X_derived <- read.csv(paste0("./data/filter_extended/", ds), header=TRUE, sep=",")
# Removing the base features
dropList <- colnames(X)
d.features <- X_derived[, !colnames(X_derived) %in% dropList]
#Selecting class
d.labels <- X[,'class']
j = 1
numberOfFeatures = ncol(d.features)
columns <- make.names(colnames(d.features))
for (column in c(columns)){
print(paste(j, 'of', numberOfFeatures, 'on', ds))
d.extX <- X_derived[, !colnames(X_derived) %in% column]
d.info <- tryCatch(
metafeatures(d.extX, d.labels, groups=c("general","statistical", "model.based" )),
error=function(e) {print(paste(e));NaN}
)
i = 1
for (info in d.info)
{
name = paste0(tolower(names(d.info)[i]))
metadata[c(column), c(name)] <- info
i = i + 1
}
j = j + 1
}
# Saving
write.csv(metadata, file = paste0("./data/mfe_ext_x/", ds))
ds
}, mc.cores=8L)
# Definition of datasets
datasets <-  list.files('./data/base/',full.names = FALSE)
metadata <- data.frame(read.csv(paste0("./data/filter_selection/", ds, ".csv"), header=TRUE, sep=","))
metadata <- data.frame(read.csv(paste0("./data/filter_selection/", ds), header=TRUE, sep=","))
rownames(metadata) <- make.names(metadata$feature, unique = TRUE)
metadata <- metadata[ , -which(names(metadata) %in% c("X"))]
print(paste("Processing ", ds, " dataset..."))
X <- read.csv(paste0("../data/base/", ds), header=TRUE, sep=",")
X <- read.csv(paste0("./data/base/", ds), header=TRUE, sep=",")
X_derived <- read.csv(paste0("./data/filter_extended/", ds), header=TRUE, sep=",")
# Removing the base features
dropList <- colnames(X)
d.features <- X_derived[, !colnames(X_derived) %in% dropList]
#Selecting class
d.labels <- X[,'class']
j = 1
numberOfFeatures = ncol(d.features)
columns <- make.names(colnames(d.features))
for (column in c(columns)){
print(paste(j, 'of', numberOfFeatures, 'on', ds))
d.info <- metafeatures(d.features[column], d.labels, groups=c("general"))
position <- 1
for (info in d.info)
{
name = paste0(tolower(names(d.info)[position]))
metadata[c(column), c(name)] <- info
position <- position + 1
}
j = j + 1
}
library(parallel)
library(mfe)
# Definition of datasets
datasets <-  list.files('./data/base/',full.names = FALSE)
mclapply(datasets, function(ds){
metadata <- data.frame(read.csv(paste0("./data/filter_selection/", ds), header=TRUE, sep=","))
rownames(metadata) <- make.names(metadata$feature, unique = TRUE)
metadata <- metadata[ , -which(names(metadata) %in% c("X"))]
print(paste("Processing ", ds, " dataset..."))
X <- read.csv(paste0("./data/base/", ds), header=TRUE, sep=",")
X_derived <- read.csv(paste0("./data/filter_extended/", ds), header=TRUE, sep=",")
# Removing the base features
dropList <- colnames(X)
d.features <- X_derived[, !colnames(X_derived) %in% dropList]
#Selecting class
d.labels <- X[,'class']
j = 1
numberOfFeatures = ncol(d.features)
columns <- make.names(colnames(d.features))
for (column in c(columns)){
print(paste(j, 'of', numberOfFeatures, 'on', ds))
d.info <- metafeatures(d.features[column], d.labels, groups=c("general"))
position <- 1
for (info in d.info)
{
name = paste0(tolower(names(d.info)[position]))
metadata[c(column), c(name)] <- info
position <- position + 1
}
j = j + 1
}
# Saving
write.csv(metadata, file = paste0("../data/mfe_x/", ds,".csv"))
ds
}, mc.cores=8L)
library(parallel)
library(mfe)
# Definition of datasets
datasets <-  list.files('./data/base/',full.names = FALSE)
mclapply(datasets, function(ds){
metadata <- data.frame(read.csv(paste0("./data/filter_selection/", ds), header=TRUE, sep=","))
rownames(metadata) <- make.names(metadata$feature, unique = TRUE)
metadata <- metadata[ , -which(names(metadata) %in% c("X"))]
print(paste("Processing ", ds, " dataset..."))
X <- read.csv(paste0("./data/base/", ds), header=TRUE, sep=",")
X_derived <- read.csv(paste0("./data/filter_extended/", ds), header=TRUE, sep=",")
# Removing the base features
dropList <- colnames(X)
d.features <- X_derived[, !colnames(X_derived) %in% dropList]
#Selecting class
d.labels <- X[,'class']
j = 1
numberOfFeatures = ncol(d.features)
columns <- make.names(colnames(d.features))
for (column in c(columns)){
print(paste(j, 'of', numberOfFeatures, 'on', ds))
d.info <- metafeatures(d.features[column], d.labels, groups=c("general"))
position <- 1
for (info in d.info)
{
name = paste0(tolower(names(d.info)[position]))
metadata[c(column), c(name)] <- info
position <- position + 1
}
j = j + 1
}
# Saving
write.csv(metadata, file = paste0("./data/mfe_x/", ds))
ds
}, mc.cores=8L)
